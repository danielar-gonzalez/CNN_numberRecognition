{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfa9f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cámara iniciada. Presiona 't' para tomar una foto y 'q' para salir.\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Procesado en 1.67s | Dígitos: 2\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Procesado en 1.21s | Dígitos: 4\n",
      "Imagen guardada como ocr_result_20250510_211941.jpg\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Forma de la entrada al modelo: (1, 32, 32, 1)\n",
      "Procesado en 1.52s | Dígitos: 5\n",
      "Imagen guardada como ocr_result_20250510_212123.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Asegúrate de que el modelo esté entrenado y cargado correctamente\n",
    "modelWin_OCR = load_model('modelWin.h5')  # Carga el modelo que tienes en memoria (modelWin)\n",
    "\n",
    "# Dimensiones esperadas por el modelo\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "# Inicializar cámara\n",
    "cap = cv2.VideoCapture(0)  # Usa 1 o 2 si tu webcam no está en el índice 0\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"❌ No se pudo acceder a la cámara. Verifica que esté conectada y no usada por otra app.\")\n",
    "\n",
    "print(\"Cámara iniciada. Presiona 't' para tomar una foto y 'q' para salir.\")\n",
    "\n",
    "while True:\n",
    "    # Leer un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"⚠️ No se pudo capturar el frame.\")\n",
    "        break\n",
    "\n",
    "    # Mostrar la vista en vivo de la cámara\n",
    "    cv2.imshow(\"Vista en Vivo\", frame)\n",
    "\n",
    "    # Esperar por una tecla para capturar la imagen\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Tomar foto cuando se presione la tecla 't'\n",
    "    if key == ord('t'):\n",
    "        start_time = time.time()  # Iniciar cronómetro para medir el tiempo de procesamiento\n",
    "        \n",
    "        # 1. Convertir a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 2. Desenfoque para reducir el ruido\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # 3. Umbral fijo o un umbral adaptativo con parámetros ajustados\n",
    "        _, thresh = cv2.threshold(blurred, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # 4. Reducción de la dilatación para evitar deformación\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "        # 5. Buscar contornos\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        digits = []  # Para almacenar los dígitos detectados\n",
    "        result_frame = frame.copy()  # Copiar la imagen para mostrarla después\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w < 10 or h < 10:\n",
    "                continue  # Ignora ruido pequeño\n",
    "\n",
    "            roi = dilated[y:y+h, x:x+w]\n",
    "            roi_resized = cv2.resize(roi, (img_width, img_height))\n",
    "            roi_resized = roi_resized.astype(\"float32\") / 255.0\n",
    "            roi_resized = np.expand_dims(roi_resized, axis=-1)  # Canal\n",
    "            roi_resized = np.expand_dims(roi_resized, axis=0)   # Batch\n",
    "\n",
    "            # Verificación de forma de la entrada antes de la predicción\n",
    "            print(f\"Forma de la entrada al modelo: {roi_resized.shape}\")\n",
    "\n",
    "            # Predicción con el modelo\n",
    "            pred = modelWin_OCR.predict(roi_resized, verbose=0)\n",
    "            label = np.argmax(pred)\n",
    "            conf = np.max(pred)\n",
    "\n",
    "            # Verificar si la confianza es suficientemente alta\n",
    "            if conf > 0.95:\n",
    "                # Dibujar predicción\n",
    "                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                text = f'{label} ({conf:.2f})'\n",
    "                cv2.putText(result_frame, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.7, (0, 0, 255), 2)\n",
    "\n",
    "                # Guardar el dígito detectado en la lista\n",
    "                digits.append(label)\n",
    "\n",
    "        # Mostrar la imagen con los resultados\n",
    "        cv2.imshow(\"Resultado OCR\", result_frame)\n",
    "        \n",
    "        # Mostrar estadísticas\n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"Procesado en {processing_time:.2f}s | Dígitos: {len(digits)}\")\n",
    "        \n",
    "        # Opción para guardar\n",
    "        save = input(\"¿Guardar resultado? (s/n): \").lower()\n",
    "        if save == 's':\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"ocr_result_{timestamp}.jpg\"\n",
    "            cv2.imwrite(filename, result_frame)\n",
    "            print(f\"Imagen guardada como {filename}\")\n",
    "\n",
    "    # Salir cuando se presiona 'q'\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
